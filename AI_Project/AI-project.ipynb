{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(\"Tumor Cancer Prediction_Data.csv\",na_values=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>F29</th>\n",
       "      <th>F30</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>10.05</td>\n",
       "      <td>17.53</td>\n",
       "      <td>64.41</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.07326</td>\n",
       "      <td>0.02511</td>\n",
       "      <td>...</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>11.16</td>\n",
       "      <td>26.84</td>\n",
       "      <td>71.98</td>\n",
       "      <td>310.8</td>\n",
       "      <td>0.06499</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>10.80</td>\n",
       "      <td>21.98</td>\n",
       "      <td>68.79</td>\n",
       "      <td>0.01844</td>\n",
       "      <td>0.08801</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.03614</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>12.76</td>\n",
       "      <td>32.04</td>\n",
       "      <td>83.69</td>\n",
       "      <td>359.9</td>\n",
       "      <td>0.07485</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>16.14</td>\n",
       "      <td>14.86</td>\n",
       "      <td>104.30</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.09495</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.08501</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>...</td>\n",
       "      <td>21.83</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>17.71</td>\n",
       "      <td>19.58</td>\n",
       "      <td>115.90</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.11290</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>12.18</td>\n",
       "      <td>17.84</td>\n",
       "      <td>77.79</td>\n",
       "      <td>0.02220</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.07057</td>\n",
       "      <td>0.02490</td>\n",
       "      <td>...</td>\n",
       "      <td>24.44</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>12.83</td>\n",
       "      <td>20.92</td>\n",
       "      <td>82.14</td>\n",
       "      <td>451.1</td>\n",
       "      <td>0.05882</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>12.25</td>\n",
       "      <td>22.44</td>\n",
       "      <td>78.18</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.05200</td>\n",
       "      <td>0.01714</td>\n",
       "      <td>...</td>\n",
       "      <td>18.04</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>14.17</td>\n",
       "      <td>31.99</td>\n",
       "      <td>92.74</td>\n",
       "      <td>466.5</td>\n",
       "      <td>0.06335</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index        F1     F2     F3      F4       F5       F6      F7       F8  \\\n",
       "0      1  0.008043  10.05  17.53   64.41  0.02100  0.10070  0.1402  0.07326   \n",
       "1      2  0.010450  10.80  21.98   68.79  0.01844  0.08801  0.1303  0.05743   \n",
       "2      3  0.008747  16.14  14.86  104.30  0.01500  0.09495  0.1206  0.08501   \n",
       "3      4  0.015190  12.18  17.84   77.79  0.02220  0.10450  0.1140  0.07057   \n",
       "4      5  0.004551  12.25  22.44   78.18  0.01608  0.08192  0.1256  0.05200   \n",
       "\n",
       "        F9  ...    F22       F23     F24       F25    F26    F27     F28  \\\n",
       "0  0.02511  ...  16.85  0.007803  0.1055  0.002778  11.16  26.84   71.98   \n",
       "1  0.03614  ...  20.20  0.006543  0.1927  0.002690  12.76  32.04   83.69   \n",
       "2  0.05500  ...  21.83  0.003958  0.2310  0.001621  17.71  19.58  115.90   \n",
       "3  0.02490  ...  24.44  0.005433  0.0498  0.003408  12.83  20.92   82.14   \n",
       "4  0.01714  ...  18.04  0.005096  0.1230  0.002399  14.17  31.99   92.74   \n",
       "\n",
       "     F29      F30  diagnosis  \n",
       "0  310.8  0.06499          B  \n",
       "1  359.9  0.07485          B  \n",
       "2  800.0  0.11290          B  \n",
       "3  451.1  0.05882          B  \n",
       "4  466.5  0.06335          B  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking duplicated rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.isna()\n",
    "import numpy \n",
    "x2=numpy.any(x)\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding non numerical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>F29</th>\n",
       "      <th>F30</th>\n",
       "      <th>diagnosis_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008043</td>\n",
       "      <td>10.05</td>\n",
       "      <td>17.53</td>\n",
       "      <td>64.41</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.07326</td>\n",
       "      <td>0.02511</td>\n",
       "      <td>0.01690</td>\n",
       "      <td>...</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>11.16</td>\n",
       "      <td>26.84</td>\n",
       "      <td>71.98</td>\n",
       "      <td>310.8</td>\n",
       "      <td>0.06499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010450</td>\n",
       "      <td>10.80</td>\n",
       "      <td>21.98</td>\n",
       "      <td>68.79</td>\n",
       "      <td>0.01844</td>\n",
       "      <td>0.08801</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.03614</td>\n",
       "      <td>0.02991</td>\n",
       "      <td>...</td>\n",
       "      <td>20.20</td>\n",
       "      <td>0.006543</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>12.76</td>\n",
       "      <td>32.04</td>\n",
       "      <td>83.69</td>\n",
       "      <td>359.9</td>\n",
       "      <td>0.07485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008747</td>\n",
       "      <td>16.14</td>\n",
       "      <td>14.86</td>\n",
       "      <td>104.30</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>0.09495</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.08501</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.01831</td>\n",
       "      <td>...</td>\n",
       "      <td>21.83</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>17.71</td>\n",
       "      <td>19.58</td>\n",
       "      <td>115.90</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.11290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015190</td>\n",
       "      <td>12.18</td>\n",
       "      <td>17.84</td>\n",
       "      <td>77.79</td>\n",
       "      <td>0.02220</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.07057</td>\n",
       "      <td>0.02490</td>\n",
       "      <td>0.01131</td>\n",
       "      <td>...</td>\n",
       "      <td>24.44</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>12.83</td>\n",
       "      <td>20.92</td>\n",
       "      <td>82.14</td>\n",
       "      <td>451.1</td>\n",
       "      <td>0.05882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004551</td>\n",
       "      <td>12.25</td>\n",
       "      <td>22.44</td>\n",
       "      <td>78.18</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>0.08192</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.05200</td>\n",
       "      <td>0.01714</td>\n",
       "      <td>0.00941</td>\n",
       "      <td>...</td>\n",
       "      <td>18.04</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>14.17</td>\n",
       "      <td>31.99</td>\n",
       "      <td>92.74</td>\n",
       "      <td>466.5</td>\n",
       "      <td>0.06335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         F1     F2     F3      F4       F5       F6      F7       F8       F9  \\\n",
       "0  0.008043  10.05  17.53   64.41  0.02100  0.10070  0.1402  0.07326  0.02511   \n",
       "1  0.010450  10.80  21.98   68.79  0.01844  0.08801  0.1303  0.05743  0.03614   \n",
       "2  0.008747  16.14  14.86  104.30  0.01500  0.09495  0.1206  0.08501  0.05500   \n",
       "3  0.015190  12.18  17.84   77.79  0.02220  0.10450  0.1140  0.07057  0.02490   \n",
       "4  0.004551  12.25  22.44   78.18  0.01608  0.08192  0.1256  0.05200  0.01714   \n",
       "\n",
       "       F10  ...    F22       F23     F24       F25    F26    F27     F28  \\\n",
       "0  0.01690  ...  16.85  0.007803  0.1055  0.002778  11.16  26.84   71.98   \n",
       "1  0.02991  ...  20.20  0.006543  0.1927  0.002690  12.76  32.04   83.69   \n",
       "2  0.01831  ...  21.83  0.003958  0.2310  0.001621  17.71  19.58  115.90   \n",
       "3  0.01131  ...  24.44  0.005433  0.0498  0.003408  12.83  20.92   82.14   \n",
       "4  0.00941  ...  18.04  0.005096  0.1230  0.002399  14.17  31.99   92.74   \n",
       "\n",
       "     F29      F30  diagnosis_M  \n",
       "0  310.8  0.06499            0  \n",
       "1  359.9  0.07485            0  \n",
       "2  800.0  0.11290            0  \n",
       "3  451.1  0.05882            0  \n",
       "4  466.5  0.06335            0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded=pd.get_dummies(df, drop_first = True)\n",
    "data_encoded= data_encoded.drop('Index',axis=1)\n",
    "\n",
    "data_encoded.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=data_encoded.iloc[:,:-2].values\n",
    "y= data_encoded.iloc[:,30:32].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Feature Scaling using Standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "st_x= StandardScaler()  \n",
    "\n",
    "x_train= st_x.fit_transform(x_train)  \n",
    "\n",
    "x_test= st_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30836262, -0.58165366, -0.29376538, ..., -0.51377611,\n",
       "        -0.71095354, -0.57534786],\n",
       "       [-0.71402037, -0.86058473, -0.55197247, ...,  0.15802668,\n",
       "        -0.79371423, -0.77750167],\n",
       "       [ 0.20256579,  1.4272136 ,  1.74137595, ...,  1.67479382,\n",
       "         1.55863327,  1.34622402],\n",
       "       ...,\n",
       "       [-0.02965175,  0.25513958, -0.86182098, ..., -0.9851604 ,\n",
       "         0.21561279,  0.086928  ],\n",
       "       [ 1.24249647,  1.27225189,  0.25081685, ...,  0.28950121,\n",
       "         0.97253442,  1.22404315],\n",
       "       [ 1.88361878,  0.04664564,  0.10997662, ..., -0.27648061,\n",
       "         0.00355692, -0.06468736]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08169812, -0.68308314,  0.19682809, ...,  0.53802014,\n",
       "        -0.58548715, -0.65809763],\n",
       "       [ 0.354012  , -0.21256304, -0.77966417, ..., -0.3630614 ,\n",
       "        -0.30097887, -0.36986185],\n",
       "       [-0.43266695,  0.30867181, -1.40170853, ..., -1.55915896,\n",
       "        -0.07007359,  0.16273567],\n",
       "       ...,\n",
       "       [-0.06835467, -0.32244498, -0.74210678, ..., -0.88575283,\n",
       "        -0.53217866, -0.38735593],\n",
       "       [-1.57171077, -0.25200784, -0.78905352, ..., -0.80237873,\n",
       "        -0.43822613, -0.32182255],\n",
       "       [-0.70661633, -1.18854006, -0.44868963, ..., -0.35825136,\n",
       "        -1.17217505, -0.99353966]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.99\n",
      "Accuracy of Logistic regression classifier on test set: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "      .format(logreg.score(x_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(x_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.99\n",
      "Accuracy of SVM classifier on test set: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(x_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(x_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a73efac36a87250835b60035ff62ea91c2bc38f1938024f13d0f7a07f37d40f3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
